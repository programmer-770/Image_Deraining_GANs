{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBNSG2oK36Pm"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNFFyv334K40"
   },
   "outputs": [],
   "source": [
    "trainA = []\n",
    "trainB = []\n",
    "for i in range(1,701):\n",
    "  img = cv2.imread('rain/{}clean.jpg'.format(i))\n",
    "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(256,256))\n",
    "  trainA.append(img)\n",
    "  img = cv2.imread('rain/{}bad.jpg'.format(i))\n",
    "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  img = cv2.resize(img,(256,256))\n",
    "  trainB.append(img)\n",
    "trainA = np.array(trainA)\n",
    "trainB = np.array(trainB)\n",
    "trainA = (trainA - 127.5)/127.5\n",
    "trainB = (trainB - 127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ROzHG-V-4_5G",
    "outputId": "3dee1b91-4361-44af-ac6c-73b0a388d4c0"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corresponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 4, 4, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 4, 4, activation='relu', padding='same')\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "\n",
    "\n",
    "    up5 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock4), mresblock3], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*4, up5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock2], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*2, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock1], axis=3)\n",
    "    mresblock8 = MultiResBlock(32, up7)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(1,1), padding='same')(mresblock8)\n",
    "    output1 = Activation('tanh')(g)    \n",
    "\n",
    "    #second encoder-decoder ##############################################################################################\n",
    "    \n",
    "    mresblock10 = MultiResBlock(32, output1)\n",
    "    pool10 = MaxPooling2D(pool_size=(2, 2))(mresblock10)\n",
    "    mresblock10 = ResPath(32, 4, mresblock10)\n",
    "\n",
    "    bridge1 = concatenate([Conv2D(32*2,(2,2),strides=(2,2),padding='same')(mresblock10), mresblock7],axis=3)\n",
    "    mresblock11 = MultiResBlock(32*2, bridge1)\n",
    "    pool11 = MaxPooling2D(pool_size=(2, 2))(mresblock11)\n",
    "    mresblock11 = ResPath(32*2, 3, mresblock11)\n",
    "    \n",
    "    bridge2 = concatenate([Conv2D(32*4,(2,2),strides=(2,2),padding='same')(mresblock11), mresblock6],axis=3)\n",
    "    mresblock12 = MultiResBlock(32*4, bridge2)\n",
    "    pool12 = MaxPooling2D(pool_size=(2, 2))(mresblock12)\n",
    "    mresblock12 = ResPath(32*4, 2, mresblock12)\n",
    "\n",
    "    bridge3 = concatenate([Conv2D(32*8,(2,2),strides=(2,2),padding='same')(mresblock12), mresblock4],axis=3)\n",
    "    mresblock13 = MultiResBlock(32*8, pool12)\n",
    "\n",
    "    up16 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock13), mresblock12, mresblock3], axis=3)\n",
    "    mresblock16 = MultiResBlock(32*4, up16)\n",
    "\n",
    "    up17 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock16), mresblock11, mresblock2], axis=3)\n",
    "    mresblock17 = MultiResBlock(32*2, up17)\n",
    "\n",
    "    up18 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock17), mresblock10, mresblock1], axis=3)\n",
    "    mresblock18 = MultiResBlock(32, up18)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(1,1), padding='same')(mresblock18)\n",
    "    output = Activation('tanh')(g)       \n",
    "    model = Model(inputs,output)\n",
    "\n",
    "    return model\n",
    "   \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    model = MultiResUnet(256, 256,3)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# plot the model\n",
    "#plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ciDO_ana4rnC",
    "outputId": "1ac41518-e07f-4e29-80c4-97a99bdc3d88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, add, Concatenate\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss= BinaryCrossentropy(from_logits=True), optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model \n",
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# create the model\n",
    "model = define_discriminator(image_shape)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "#plot_model(model, to_file='/content/drive/My Drive/test/discriminator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxxLHXUB7Acc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    in_target = Input(shape = image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model([in_src,in_target], [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=[BinaryCrossentropy(from_logits=True), 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8F9AX90NtAE"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\n",
    "\t# choose random instances\n",
    "\tix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nizFt9ZoOBZN"
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(samples)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S665N71aOD0x"
   },
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, d_model, gan_model, n_samples=1):\n",
    "\t# select a sample of input images\n",
    "\t[X_realA, X_realB], _ = generate_real_samples(n_samples, 1)\n",
    "\t# generate a batch of fake samples\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "\tX_realA = (X_realA + 1) / 2.0\n",
    "\tX_realB = (X_realB + 1) / 2.0\n",
    "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
    "\tX_fakeB = 255 * X_fakeB\t\n",
    "\t# plot generated target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_fakeB[i])\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'test3/plot_%06d.png' % (step+1)\n",
    "\tcv2.imwrite(filename1,X_fakeB[0])\n",
    "\t# save the generator, discriminator and gan models\n",
    "\tfilename2 = 'test3/g_model_%06d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\t#filename3 = 'test/d_model_%06d.h5' % (step+1)\n",
    "\t#d_model.save(filename3)\n",
    "\t#filename4 = 'test/gan_model_%06d.h5' % (step+1)\n",
    "\t#gan_model.save(filename4)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmJm9v64ORWY"
   },
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, n_epochs=1000, n_batch=1, n_patch=32):\n",
    "\t# unpack dataset\n",
    "  \n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# select a batch of real samples\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples( n_batch, n_patch)\n",
    "\t\t# generate a batch of fake samples\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realB, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realB, X_realA], y_real)\n",
    "\t\t# update discriminator for generated samples\n",
    "\t\td_loss2 = d_model.train_on_batch([X_realB, X_fakeB], y_fake)\n",
    "\t\t# update the generator\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch([X_realB,X_realA], [y_fake, X_realA])\n",
    "\t\t# summarize performance\n",
    "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "    # summarize model performance\n",
    "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
    "\t\t\tsummarize_performance(i, g_model,d_model, gan_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UNNPPKOOyVT"
   },
   "outputs": [],
   "source": [
    "image_shape = (256,256,3)\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = MultiResUnet(256,256,3)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# train model\n",
    "train(d_model, g_model, gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KskiUCTgPM4b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "multi-res-unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
