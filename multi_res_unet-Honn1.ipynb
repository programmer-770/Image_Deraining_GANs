{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBNSG2oK36Pm"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNFFyv334K40"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-331b0f2ca18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrainA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtrainB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrainB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainA = []\n",
    "trainB = []\n",
    "for i in range(1,901):\n",
    "  for j in range(1,15):\n",
    "      img = cv2.imread('ground_truth/{}.jpg'.format(i))\n",
    "      img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "      img = cv2.resize(img,(256,256))\n",
    "      trainA.append(img)\n",
    "      img = cv2.imread('rainy_image/{}_{}.jpg'.format(i,j))\n",
    "      img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "      img = cv2.resize(img,(256,256))\n",
    "      trainB.append(img)\n",
    "trainA = np.array(trainA)\n",
    "trainB = np.array(trainB)\n",
    "trainA = (trainA - 127.5)/127.5\n",
    "trainB = (trainB - 127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ROzHG-V-4_5G",
    "outputId": "3dee1b91-4361-44af-ac6c-73b0a388d4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 256, 256, 8)  384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 256, 256, 8)  24          conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 256, 256, 8)  0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 256, 256, 17) 2176        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 256, 256, 17) 51          conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 256, 256, 17) 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 256, 256, 26) 7072        activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 256, 256, 26) 78          conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 256, 256, 26) 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 256, 256, 51) 153         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 256, 256, 51) 0           activation_191[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 256, 256, 51) 153         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 256, 256, 51) 204         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 256, 256, 51) 0           batch_normalization_283[0][0]    \n",
      "                                                                 batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 256, 256, 51) 0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 256, 256, 51) 204         activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 128, 128, 51) 0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 128, 128, 17) 13872       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 128, 128, 17) 51          conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 128, 128, 17) 0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 128, 128, 35) 9520        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 128, 128, 35) 105         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 128, 128, 35) 0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 128, 128, 53) 29680       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 128, 128, 53) 159         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 128, 128, 53) 0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 128, 128, 105 5355        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 128, 128, 105 0           activation_203[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 128, 128, 105 315         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 128, 128, 105 420         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 128, 128, 105 0           batch_normalization_301[0][0]    \n",
      "                                                                 batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 128, 128, 105 0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 128, 128, 105 420         activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 64, 64, 105)  0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 64, 64, 35)   58800       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 64, 64, 35)   105         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 64, 64, 35)   0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 64, 64, 71)   39760       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 64, 64, 71)   213         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 64, 64, 71)   0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 64, 64, 106)  120416      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 64, 64, 106)  318         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 64, 64, 106)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 64, 64, 212)  22260       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 64, 64, 212)  0           activation_213[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 64, 64, 212)  636         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 64, 64, 212)  848         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 64, 64, 212)  0           batch_normalization_316[0][0]    \n",
      "                                                                 batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 64, 64, 212)  0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 64, 64, 212)  848         activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 32, 212)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 71)   240832      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 32, 32, 71)   213         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 71)   0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 32, 32, 142)  161312      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 64, 64, 128)  434176      batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 32, 32, 142)  426         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 64, 64, 128)  27136       batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 64, 64, 128)  384         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 142)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 64, 64, 128)  384         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 64, 64, 128)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 32, 32, 213)  483936      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 64, 64, 128)  0           batch_normalization_322[0][0]    \n",
      "                                                                 activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 32, 32, 213)  639         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 64, 64, 128)  0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 213)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 64, 64, 128)  512         activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 426)  90312       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 32, 32, 426)  0           activation_221[0][0]             \n",
      "                                                                 activation_222[0][0]             \n",
      "                                                                 activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 64, 64, 128)  262144      batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 32, 32, 426)  1278        conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 32, 32, 426)  1704        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 64, 64, 128)  16384       batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 64, 64, 128)  384         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 32, 32, 426)  0           batch_normalization_328[0][0]    \n",
      "                                                                 batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 64, 64, 128)  384         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 64, 64, 128)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 426)  0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 64, 64, 128)  0           batch_normalization_325[0][0]    \n",
      "                                                                 activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 32, 32, 426)  1704        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 64, 64, 128)  0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 128, 128, 64) 107520      batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTran (None, 64, 64, 128)  218240      batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 64, 64, 128)  512         activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 128, 128, 64) 6720        batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 128, 128, 64) 192         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 64, 64, 256)  0           conv2d_transpose_17[0][0]        \n",
      "                                                                 batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 128, 128, 64) 192         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 128, 128, 64) 0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 64, 64, 35)   143360      concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 128, 128, 64) 0           batch_normalization_307[0][0]    \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 64, 64, 35)   105         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 128, 128, 64) 0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 64, 64, 35)   0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 128, 128, 64) 256         activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 64, 64, 71)   39760       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 128, 128, 64) 65536       batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 64, 64, 71)   213         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 128, 128, 64) 4096        batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 128, 128, 64) 192         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 64, 64, 71)   0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 128, 128, 64) 192         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 128, 128, 64) 0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 64, 64, 106)  120416      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 128, 128, 64) 0           batch_normalization_310[0][0]    \n",
      "                                                                 activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 64, 64, 106)  318         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 128, 128, 64) 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 256, 256, 32) 26112       batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 64, 64, 106)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 128, 128, 64) 256         activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 256, 256, 32) 1632        batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 256, 256, 32) 96          conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 64, 64, 212)  54272       concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 64, 64, 212)  0           activation_225[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 128, 128, 64) 65536       batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 256, 256, 32) 96          conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 256, 256, 32) 0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 64, 64, 212)  636         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 64, 64, 212)  848         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 128, 128, 64) 4096        batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 128, 128, 64) 192         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 256, 256, 32) 0           batch_normalization_289[0][0]    \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 64, 64, 212)  0           batch_normalization_334[0][0]    \n",
      "                                                                 batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 128, 128, 64) 192         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 128, 128, 64) 0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 256, 256, 32) 0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 64, 64, 212)  0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 128, 128, 64) 0           batch_normalization_313[0][0]    \n",
      "                                                                 activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 256, 256, 32) 128         activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 64, 64, 212)  848         activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 128, 128, 64) 0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTran (None, 128, 128, 64) 54336       batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 128, 128, 64) 256         activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 256, 256, 32) 96          conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_18[0][0]        \n",
      "                                                                 batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 256, 256, 32) 96          conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 256, 256, 32) 0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 128, 128, 17) 34816       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 256, 256, 32) 0           batch_normalization_292[0][0]    \n",
      "                                                                 activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 128, 128, 17) 51          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 256, 256, 32) 0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 128, 128, 17) 0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 256, 256, 32) 128         activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 128, 128, 35) 9520        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 128, 128, 35) 105         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 256, 256, 32) 96          conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 128, 128, 35) 0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 256, 256, 32) 96          conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 256, 256, 32) 0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 128, 128, 53) 29680       activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 256, 256, 32) 0           batch_normalization_295[0][0]    \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 128, 128, 53) 159         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 256, 256, 32) 0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 128, 128, 53) 0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 256, 256, 32) 128         activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 128, 128, 105 13440       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 128, 128, 105 0           activation_229[0][0]             \n",
      "                                                                 activation_230[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 128, 128, 105 315         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 128, 128, 105 420         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 256, 256, 32) 96          conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 128, 128, 105 0           batch_normalization_340[0][0]    \n",
      "                                                                 batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 256, 256, 32) 96          conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 256, 256, 32) 0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 128, 128, 105 0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 256, 256, 32) 0           batch_normalization_298[0][0]    \n",
      "                                                                 activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 128, 128, 105 420         activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 256, 256, 32) 0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTran (None, 256, 256, 32) 13472       batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 256, 256, 32) 128         activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 256, 256, 64) 0           conv2d_transpose_19[0][0]        \n",
      "                                                                 batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 256, 256, 8)  8192        concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 256, 256, 8)  24          conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 256, 256, 8)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 256, 256, 17) 2176        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 256, 256, 17) 51          conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 256, 256, 17) 0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 256, 256, 26) 7072        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 256, 256, 26) 78          conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 256, 256, 26) 0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 256, 256, 51) 3264        concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 256, 256, 51) 0           activation_233[0][0]             \n",
      "                                                                 activation_234[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 256, 256, 51) 153         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 256, 256, 51) 204         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 256, 256, 51) 0           batch_normalization_346[0][0]    \n",
      "                                                                 batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 256, 256, 51) 0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 256, 256, 51) 204         activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 256, 256, 3)  2451        batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 256, 256, 3)  0           conv2d_transpose_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 256, 256, 8)  384         activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 256, 256, 8)  24          conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 256, 256, 8)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 256, 256, 17) 2176        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 256, 256, 17) 51          conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 256, 256, 17) 0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 256, 256, 26) 7072        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 256, 256, 26) 78          conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 256, 256, 26) 0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 256, 256, 51) 153         activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 256, 256, 51) 0           activation_238[0][0]             \n",
      "                                                                 activation_239[0][0]             \n",
      "                                                                 activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 256, 256, 51) 153         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 256, 256, 51) 204         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 256, 256, 51) 0           batch_normalization_352[0][0]    \n",
      "                                                                 batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 256, 256, 51) 0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 256, 256, 51) 204         activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 256, 256, 32) 26112       batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 256, 256, 32) 1632        batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 256, 256, 32) 96          conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 256, 256, 32) 96          conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 256, 256, 32) 0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 256, 256, 32) 0           batch_normalization_358[0][0]    \n",
      "                                                                 activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 256, 256, 32) 0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 256, 256, 32) 128         activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 256, 256, 32) 96          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 256, 256, 32) 96          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 256, 256, 32) 0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 256, 256, 32) 0           batch_normalization_361[0][0]    \n",
      "                                                                 activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 256, 256, 32) 0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 256, 256, 32) 128         activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 256, 256, 32) 96          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 256, 256, 32) 96          conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 256, 256, 32) 0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 256, 256, 32) 0           batch_normalization_364[0][0]    \n",
      "                                                                 activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 256, 256, 32) 0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 256, 256, 32) 128         activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 256, 256, 32) 16384       batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 256, 256, 32) 1024        batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 256, 256, 32) 96          conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 256, 256, 32) 96          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 256, 256, 32) 0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 256, 256, 32) 0           batch_normalization_367[0][0]    \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 256, 256, 32) 0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 256, 256, 32) 128         activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 128, 128, 64) 8256        batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 128, 128, 169 0           conv2d_259[0][0]                 \n",
      "                                                                 batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 128, 128, 17) 45968       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 128, 128, 17) 51          conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 128, 128, 17) 0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 128, 128, 35) 9520        activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 128, 128, 35) 105         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 128, 128, 35) 0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 128, 128, 53) 29680       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 128, 128, 53) 159         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 128, 128, 53) 0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 128, 128, 105 17745       concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 128, 128, 105 0           activation_250[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 128, 128, 105 315         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 128, 128, 105 420         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 128, 128, 105 0           batch_normalization_370[0][0]    \n",
      "                                                                 batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 128, 128, 105 0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 128, 128, 105 420         activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 128, 128, 64) 107520      batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 128, 128, 64) 6720        batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 128, 128, 64) 192         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 128, 128, 64) 192         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 128, 128, 64) 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 128, 128, 64) 0           batch_normalization_376[0][0]    \n",
      "                                                                 activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 128, 128, 64) 0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 128, 128, 64) 256         activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 128, 128, 64) 65536       batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 128, 128, 64) 4096        batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 128, 128, 64) 192         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 128, 128, 64) 192         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 128, 128, 64) 0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 128, 128, 64) 0           batch_normalization_379[0][0]    \n",
      "                                                                 activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 128, 128, 64) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 128, 128, 64) 256         activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 128, 128, 64) 65536       batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 128, 128, 64) 4096        batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 128, 128, 64) 192         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 128, 128, 64) 192         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 128, 128, 64) 0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 128, 128, 64) 0           batch_normalization_382[0][0]    \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 128, 128, 64) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 128, 128, 64) 256         activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 64, 64, 128)  32896       batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 64, 64, 340)  0           conv2d_270[0][0]                 \n",
      "                                                                 batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 64, 64, 35)   190400      concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 64, 64, 35)   105         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 64, 64, 35)   0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 64, 64, 71)   39760       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 64, 64, 71)   213         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 64, 64, 71)   0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 64, 64, 106)  120416      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 64, 64, 106)  318         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 64, 64, 106)  0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 64, 64, 212)  72080       concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 64, 64, 212)  0           activation_260[0][0]             \n",
      "                                                                 activation_261[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 64, 64, 212)  636         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 64, 64, 212)  848         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 64, 64, 212)  0           batch_normalization_385[0][0]    \n",
      "                                                                 batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 64, 64, 212)  0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 64, 64, 212)  848         activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 32, 32, 212)  0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 32, 32, 71)   240832      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 32, 32, 71)   213         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 32, 32, 71)   0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 32, 32, 142)  161312      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 64, 64, 128)  434176      batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 32, 32, 142)  426         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 64, 64, 128)  27136       batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 64, 64, 128)  384         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 32, 32, 142)  0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 64, 64, 128)  384         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 64, 64, 128)  0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 32, 32, 213)  483936      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 64, 64, 128)  0           batch_normalization_391[0][0]    \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 32, 32, 213)  639         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 64, 64, 128)  0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 32, 32, 213)  0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 64, 64, 128)  512         activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 32, 32, 426)  90312       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 32, 32, 426)  0           activation_268[0][0]             \n",
      "                                                                 activation_269[0][0]             \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 64, 64, 128)  262144      batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 32, 32, 426)  1278        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 32, 32, 426)  1704        concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 64, 64, 128)  16384       batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 64, 64, 128)  384         conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 32, 32, 426)  0           batch_normalization_397[0][0]    \n",
      "                                                                 batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 64, 64, 128)  384         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 64, 64, 128)  0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 32, 32, 426)  0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 64, 64, 128)  0           batch_normalization_394[0][0]    \n",
      "                                                                 activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 32, 32, 426)  1704        activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 64, 64, 128)  0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 64, 64, 128)  218240      batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 64, 64, 128)  512         activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 64, 64, 384)  0           conv2d_transpose_21[0][0]        \n",
      "                                                                 batch_normalization_396[0][0]    \n",
      "                                                                 batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 64, 64, 35)   215040      concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 64, 64, 35)   105         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 64, 64, 35)   0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 64, 64, 71)   39760       activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 64, 64, 71)   213         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 64, 64, 71)   0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 64, 64, 106)  120416      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 64, 64, 106)  318         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 64, 64, 106)  0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 64, 64, 212)  81408       concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 64, 64, 212)  0           activation_272[0][0]             \n",
      "                                                                 activation_273[0][0]             \n",
      "                                                                 activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 64, 64, 212)  636         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 64, 64, 212)  848         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 64, 64, 212)  0           batch_normalization_403[0][0]    \n",
      "                                                                 batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 64, 64, 212)  0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 64, 64, 212)  848         activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 128, 128, 64) 54336       batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 128, 128, 192 0           conv2d_transpose_22[0][0]        \n",
      "                                                                 batch_normalization_384[0][0]    \n",
      "                                                                 batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 128, 128, 17) 52224       concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 128, 128, 17) 51          conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 128, 128, 17) 0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 128, 128, 35) 9520        activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 128, 128, 35) 105         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 128, 128, 35) 0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 128, 128, 53) 29680       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 128, 128, 53) 159         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 128, 128, 53) 0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 128, 128, 105 20160       concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 128, 128, 105 0           activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "                                                                 activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 128, 128, 105 315         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 128, 128, 105 420         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 128, 128, 105 0           batch_normalization_409[0][0]    \n",
      "                                                                 batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 128, 128, 105 0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 128, 128, 105 420         activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 256, 256, 32) 13472       batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 256, 256, 96) 0           conv2d_transpose_23[0][0]        \n",
      "                                                                 batch_normalization_369[0][0]    \n",
      "                                                                 batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 256, 256, 8)  12288       concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 256, 256, 8)  24          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 256, 256, 8)  0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 256, 256, 17) 2176        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 256, 256, 17) 51          conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 256, 256, 17) 0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 256, 256, 26) 7072        activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 256, 256, 26) 78          conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 256, 256, 26) 0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 256, 256, 51) 4896        concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 256, 256, 51) 0           activation_280[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 256, 256, 51) 153         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 256, 256, 51) 204         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 256, 256, 51) 0           batch_normalization_415[0][0]    \n",
      "                                                                 batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 256, 256, 51) 0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 256, 256, 51) 204         activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 256, 256, 3)  2451        batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 256, 256, 3)  0           conv2d_transpose_24[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 6,667,024\n",
      "Trainable params: 6,641,520\n",
      "Non-trainable params: 25,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corresponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 4, 4,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 4, 4, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 4, 4, activation='relu', padding='same')\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def MultiResUnet(height, width, n_channels):\n",
    "    '''\n",
    "    MultiResUNet\n",
    "    \n",
    "    Arguments:\n",
    "        height {int} -- height of image \n",
    "        width {int} -- width of image \n",
    "        n_channels {int} -- number of channels in image\n",
    "    \n",
    "    Returns:\n",
    "        [keras model] -- MultiResUNet model\n",
    "    '''\n",
    "\n",
    "\n",
    "    inputs = Input((height, width, n_channels))\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "\n",
    "\n",
    "    up5 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock4), mresblock3], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*4, up5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock2], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*2, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(\n",
    "        32, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock1], axis=3)\n",
    "    mresblock8 = MultiResBlock(32, up7)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(1,1), padding='same')(mresblock8)\n",
    "    output1 = Activation('tanh')(g)    \n",
    "\n",
    "    #second encoder-decoder ##############################################################################################\n",
    "    \n",
    "    mresblock10 = MultiResBlock(32, output1)\n",
    "    pool10 = MaxPooling2D(pool_size=(2, 2))(mresblock10)\n",
    "    mresblock10 = ResPath(32, 4, mresblock10)\n",
    "\n",
    "    bridge1 = concatenate([Conv2D(32*2,(2,2),strides=(2,2),padding='same')(mresblock10), mresblock7],axis=3)\n",
    "    mresblock11 = MultiResBlock(32*2, bridge1)\n",
    "    pool11 = MaxPooling2D(pool_size=(2, 2))(mresblock11)\n",
    "    mresblock11 = ResPath(32*2, 3, mresblock11)\n",
    "    \n",
    "    bridge2 = concatenate([Conv2D(32*4,(2,2),strides=(2,2),padding='same')(mresblock11), mresblock6],axis=3)\n",
    "    mresblock12 = MultiResBlock(32*4, bridge2)\n",
    "    pool12 = MaxPooling2D(pool_size=(2, 2))(mresblock12)\n",
    "    mresblock12 = ResPath(32*4, 2, mresblock12)\n",
    "\n",
    "    bridge3 = concatenate([Conv2D(32*8,(2,2),strides=(2,2),padding='same')(mresblock12), mresblock4],axis=3)\n",
    "    mresblock13 = MultiResBlock(32*8, pool12)\n",
    "\n",
    "    up16 = concatenate([Conv2DTranspose(\n",
    "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock13), mresblock12, mresblock3], axis=3)\n",
    "    mresblock16 = MultiResBlock(32*4, up16)\n",
    "\n",
    "    up17 = concatenate([Conv2DTranspose(\n",
    "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock16), mresblock11, mresblock2], axis=3)\n",
    "    mresblock17 = MultiResBlock(32*2, up17)\n",
    "\n",
    "    up18 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock17), mresblock10, mresblock1], axis=3)\n",
    "    mresblock18 = MultiResBlock(32, up18)\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(1,1), padding='same')(mresblock18)\n",
    "    output = Activation('tanh')(g)       \n",
    "    model = Model(inputs,output)\n",
    "\n",
    "    return model\n",
    "   \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Define the model\n",
    "\n",
    "    model = MultiResUnet(256, 256,3)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# plot the model\n",
    "#plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ciDO_ana4rnC",
    "outputId": "1ac41518-e07f-4e29-80c4-97a99bdc3d88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 256, 256, 6)  0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 128, 128, 64) 6208        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 64, 64, 128)  131200      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 64, 64, 128)  512         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 32, 32, 256)  524544      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 32, 32, 256)  1024        conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 32, 32, 256)  1048832     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 32, 32, 256)  1024        conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 32, 32, 1)    4097        leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 32, 32, 1)    0           conv2d_300[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,717,441\n",
      "Trainable params: 1,716,161\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, add, Concatenate\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model \n",
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# create the model\n",
    "model = define_discriminator(image_shape)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "#plot_model(model, to_file='/content/drive/My Drive/test/discriminator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxxLHXUB7Acc"
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8F9AX90NtAE"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\n",
    "\t# choose random instances\n",
    "\tix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nizFt9ZoOBZN"
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(samples)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S665N71aOD0x"
   },
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, d_model, gan_model, n_samples=1):\n",
    "\t# select a sample of input images\n",
    "\t[X_realA, X_realB], _ = generate_real_samples(n_samples, 1)\n",
    "\t# generate a batch of fake samples\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# scale all pixels from [-1,1] to [0,1]\n",
    "\tX_realA = (X_realA + 1) / 2.0\n",
    "\tX_realB = (X_realB + 1) / 2.0\n",
    "\tX_fakeB = (X_fakeB + 1) / 2.0\n",
    "\tX_fakeB = 255 * X_fakeB\t\n",
    "\t# plot generated target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_fakeB[i])\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'test/plot_%06d.png' % (step+1)\n",
    "\tcv2.imwrite(filename1,X_fakeB[0])\n",
    "\t# save the generator, discriminator and gan models\n",
    "\tfilename2 = 'test/g_model_%06d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\t#filename3 = 'test/d_model_%06d.h5' % (step+1)\n",
    "\t#d_model.save(filename3)\n",
    "\t#filename4 = 'test/gan_model_%06d.h5' % (step+1)\n",
    "\t#gan_model.save(filename4)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmJm9v64ORWY"
   },
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, n_epochs=200, n_batch=1, n_patch=32):\n",
    "\t# unpack dataset\n",
    "  \n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# select a batch of real samples\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples( n_batch, n_patch)\n",
    "\t\t# generate a batch of fake samples\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realB, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realB, X_realA], y_real)\n",
    "\t\t# update discriminator for generated samples\n",
    "\t\td_loss2 = d_model.train_on_batch([X_fakeB, X_realA], y_fake)\n",
    "\t\t# update the generator\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realB, [y_real, X_realA])\n",
    "\t\t# summarize performance\n",
    "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "    # summarize model performance\n",
    "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
    "\t\t\tsummarize_performance(i, g_model,d_model, gan_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UNNPPKOOyVT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7944b63591e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# define the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiResUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# define the composite model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'define_discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "image_shape = (256,256,3)\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = MultiResUnet(256,256,3)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# train model\n",
    "train(d_model, g_model, gan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KskiUCTgPM4b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "multi-res-unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
